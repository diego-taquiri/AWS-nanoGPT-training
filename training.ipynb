{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 1,115,394\n",
      "all the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n",
      "train has 1,003,854 tokens\n",
      "val has 111,540 tokens\n"
     ]
    }
   ],
   "source": [
    "!python data/shakespeare_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_shakespeare_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-shakespeare-char'\n",
      "eval_interval = 250 # keep frequent because we'll overfit\n",
      "eval_iters = 200\n",
      "log_interval = 10 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = False # override via command line if you like\n",
      "wandb_project = 'shakespeare-char'\n",
      "wandb_run_name = 'mini-gpt'\n",
      "\n",
      "dataset = 'shakespeare_char'\n",
      "gradient_accumulation_steps = 1\n",
      "batch_size = 64\n",
      "block_size = 256 # context of up to 256 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 6\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 100 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "tokens per iteration will be: 16,384\n",
      "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 10.65M\n",
      "/home/ubuntu/diego/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
      "num decayed parameter tensors: 26, with 10,740,096 parameters\n",
      "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
      "using fused AdamW: True\n",
      "step 0: train loss 4.2874, val loss 4.2823\n",
      "iter 0: loss 4.2663, time 59716.44ms, mfu -100.00%\n",
      "iter 10: loss 3.2415, time 442.40ms, mfu 0.84%\n",
      "iter 20: loss 2.7773, time 445.04ms, mfu 0.84%\n",
      "iter 30: loss 2.6325, time 443.56ms, mfu 0.84%\n",
      "iter 40: loss 2.5809, time 446.48ms, mfu 0.84%\n",
      "iter 50: loss 2.5302, time 441.84ms, mfu 0.84%\n",
      "iter 60: loss 2.5133, time 447.85ms, mfu 0.84%\n",
      "iter 70: loss 2.4994, time 448.68ms, mfu 0.84%\n",
      "iter 80: loss 2.4967, time 448.13ms, mfu 0.84%\n",
      "iter 90: loss 2.4683, time 448.29ms, mfu 0.84%\n",
      "iter 100: loss 2.4540, time 445.01ms, mfu 0.84%\n",
      "iter 110: loss 2.4559, time 447.61ms, mfu 0.84%\n",
      "iter 120: loss 2.4273, time 450.92ms, mfu 0.84%\n",
      "iter 130: loss 2.4141, time 449.07ms, mfu 0.84%\n",
      "iter 140: loss 2.4085, time 450.52ms, mfu 0.83%\n",
      "iter 150: loss 2.4139, time 448.84ms, mfu 0.83%\n",
      "iter 160: loss 2.3872, time 448.33ms, mfu 0.83%\n",
      "iter 170: loss 2.3656, time 447.96ms, mfu 0.83%\n",
      "iter 180: loss 2.3346, time 449.35ms, mfu 0.83%\n",
      "iter 190: loss 2.2522, time 445.45ms, mfu 0.83%\n",
      "iter 200: loss 2.2124, time 449.21ms, mfu 0.83%\n",
      "iter 210: loss 2.1425, time 449.95ms, mfu 0.83%\n",
      "iter 220: loss 2.1396, time 447.23ms, mfu 0.83%\n",
      "iter 230: loss 2.0699, time 447.89ms, mfu 0.83%\n",
      "iter 240: loss 2.0773, time 447.31ms, mfu 0.83%\n",
      "step 250: train loss 1.9603, val loss 2.0625\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 250: loss 2.0334, time 61371.87ms, mfu 0.75%\n",
      "iter 260: loss 1.9740, time 450.18ms, mfu 0.76%\n",
      "iter 270: loss 1.9761, time 448.35ms, mfu 0.77%\n",
      "iter 280: loss 1.9769, time 450.67ms, mfu 0.77%\n",
      "iter 290: loss 1.9198, time 450.93ms, mfu 0.78%\n",
      "iter 300: loss 1.8993, time 449.92ms, mfu 0.78%\n",
      "iter 310: loss 1.8603, time 449.87ms, mfu 0.79%\n",
      "iter 320: loss 1.8423, time 450.47ms, mfu 0.79%\n",
      "iter 330: loss 1.8175, time 452.74ms, mfu 0.79%\n",
      "iter 340: loss 1.7864, time 451.06ms, mfu 0.80%\n",
      "iter 350: loss 1.8223, time 450.77ms, mfu 0.80%\n",
      "iter 360: loss 1.7633, time 451.45ms, mfu 0.80%\n",
      "iter 370: loss 1.7338, time 449.85ms, mfu 0.81%\n",
      "iter 380: loss 1.7246, time 449.22ms, mfu 0.81%\n",
      "iter 390: loss 1.7325, time 448.82ms, mfu 0.81%\n",
      "iter 400: loss 1.7604, time 449.42ms, mfu 0.81%\n",
      "iter 410: loss 1.6918, time 448.79ms, mfu 0.81%\n",
      "iter 420: loss 1.7096, time 448.01ms, mfu 0.82%\n",
      "iter 430: loss 1.6813, time 447.28ms, mfu 0.82%\n",
      "iter 440: loss 1.6590, time 449.42ms, mfu 0.82%\n",
      "iter 450: loss 1.6554, time 446.74ms, mfu 0.82%\n",
      "iter 460: loss 1.5988, time 449.42ms, mfu 0.82%\n",
      "iter 470: loss 1.6582, time 448.16ms, mfu 0.82%\n",
      "iter 480: loss 1.6124, time 446.87ms, mfu 0.82%\n",
      "iter 490: loss 1.5978, time 448.30ms, mfu 0.82%\n",
      "step 500: train loss 1.5285, val loss 1.7363\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 500: loss 1.6009, time 61742.37ms, mfu 0.74%\n",
      "iter 510: loss 1.6044, time 450.85ms, mfu 0.75%\n",
      "iter 520: loss 1.5897, time 448.89ms, mfu 0.76%\n",
      "iter 530: loss 1.5622, time 448.83ms, mfu 0.77%\n",
      "iter 540: loss 1.6223, time 451.11ms, mfu 0.77%\n",
      "iter 550: loss 1.5618, time 449.96ms, mfu 0.78%\n",
      "iter 560: loss 1.5650, time 449.72ms, mfu 0.78%\n",
      "iter 570: loss 1.5577, time 452.21ms, mfu 0.79%\n",
      "iter 580: loss 1.5405, time 450.74ms, mfu 0.79%\n",
      "iter 590: loss 1.4950, time 448.27ms, mfu 0.79%\n",
      "iter 600: loss 1.5179, time 449.88ms, mfu 0.80%\n",
      "iter 610: loss 1.5439, time 447.37ms, mfu 0.80%\n",
      "iter 620: loss 1.5242, time 448.78ms, mfu 0.80%\n",
      "iter 630: loss 1.5114, time 448.08ms, mfu 0.81%\n",
      "iter 640: loss 1.4651, time 449.16ms, mfu 0.81%\n",
      "iter 650: loss 1.5014, time 445.23ms, mfu 0.81%\n",
      "iter 660: loss 1.5024, time 448.35ms, mfu 0.81%\n",
      "iter 670: loss 1.4496, time 449.24ms, mfu 0.82%\n",
      "iter 680: loss 1.5093, time 446.22ms, mfu 0.82%\n",
      "iter 690: loss 1.4644, time 447.86ms, mfu 0.82%\n",
      "iter 700: loss 1.4798, time 449.67ms, mfu 0.82%\n",
      "iter 710: loss 1.4571, time 448.91ms, mfu 0.82%\n",
      "iter 720: loss 1.4425, time 450.64ms, mfu 0.82%\n",
      "iter 730: loss 1.4247, time 448.46ms, mfu 0.82%\n",
      "iter 740: loss 1.4248, time 452.18ms, mfu 0.82%\n",
      "step 750: train loss 1.3586, val loss 1.5802\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 750: loss 1.4240, time 61826.95ms, mfu 0.74%\n",
      "iter 760: loss 1.4382, time 449.84ms, mfu 0.75%\n",
      "iter 770: loss 1.4208, time 448.86ms, mfu 0.76%\n",
      "iter 780: loss 1.4244, time 448.74ms, mfu 0.77%\n",
      "iter 790: loss 1.4173, time 446.60ms, mfu 0.77%\n",
      "iter 800: loss 1.4272, time 448.32ms, mfu 0.78%\n",
      "iter 810: loss 1.4026, time 448.61ms, mfu 0.78%\n",
      "iter 820: loss 1.4056, time 449.01ms, mfu 0.79%\n",
      "iter 830: loss 1.3859, time 450.21ms, mfu 0.79%\n",
      "iter 840: loss 1.4046, time 450.24ms, mfu 0.80%\n",
      "iter 850: loss 1.3911, time 448.99ms, mfu 0.80%\n",
      "iter 860: loss 1.3952, time 448.81ms, mfu 0.80%\n",
      "iter 870: loss 1.3935, time 452.21ms, mfu 0.80%\n",
      "iter 880: loss 1.3804, time 446.76ms, mfu 0.81%\n",
      "iter 890: loss 1.3896, time 448.24ms, mfu 0.81%\n",
      "iter 900: loss 1.3723, time 449.34ms, mfu 0.81%\n",
      "iter 910: loss 1.3200, time 449.02ms, mfu 0.81%\n",
      "iter 920: loss 1.3567, time 450.14ms, mfu 0.81%\n",
      "iter 930: loss 1.3608, time 448.47ms, mfu 0.82%\n",
      "iter 940: loss 1.3417, time 449.66ms, mfu 0.82%\n",
      "iter 950: loss 1.3493, time 450.72ms, mfu 0.82%\n",
      "iter 960: loss 1.3658, time 448.73ms, mfu 0.82%\n",
      "iter 970: loss 1.3574, time 450.94ms, mfu 0.82%\n",
      "iter 980: loss 1.3562, time 451.02ms, mfu 0.82%\n",
      "iter 990: loss 1.3345, time 448.48ms, mfu 0.82%\n",
      "step 1000: train loss 1.2713, val loss 1.5264\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1000: loss 1.3294, time 61698.55ms, mfu 0.74%\n",
      "iter 1010: loss 1.3296, time 449.19ms, mfu 0.75%\n",
      "iter 1020: loss 1.3039, time 449.03ms, mfu 0.76%\n",
      "iter 1030: loss 1.3317, time 448.53ms, mfu 0.76%\n",
      "iter 1040: loss 1.3616, time 450.99ms, mfu 0.77%\n",
      "iter 1050: loss 1.2993, time 448.01ms, mfu 0.78%\n",
      "iter 1060: loss 1.3393, time 448.64ms, mfu 0.78%\n",
      "iter 1070: loss 1.3390, time 450.00ms, mfu 0.79%\n",
      "iter 1080: loss 1.3430, time 447.94ms, mfu 0.79%\n",
      "iter 1090: loss 1.3509, time 450.81ms, mfu 0.79%\n",
      "iter 1100: loss 1.3211, time 448.95ms, mfu 0.80%\n",
      "iter 1110: loss 1.3000, time 451.48ms, mfu 0.80%\n",
      "iter 1120: loss 1.3048, time 449.98ms, mfu 0.80%\n",
      "iter 1130: loss 1.2967, time 447.69ms, mfu 0.81%\n",
      "iter 1140: loss 1.2980, time 449.59ms, mfu 0.81%\n",
      "iter 1150: loss 1.3068, time 452.27ms, mfu 0.81%\n",
      "iter 1160: loss 1.3254, time 450.01ms, mfu 0.81%\n",
      "iter 1170: loss 1.2981, time 451.34ms, mfu 0.81%\n",
      "iter 1180: loss 1.3218, time 451.38ms, mfu 0.81%\n",
      "iter 1190: loss 1.2697, time 448.78ms, mfu 0.82%\n",
      "iter 1200: loss 1.2983, time 452.61ms, mfu 0.82%\n",
      "iter 1210: loss 1.2639, time 449.89ms, mfu 0.82%\n",
      "iter 1220: loss 1.3060, time 449.79ms, mfu 0.82%\n",
      "iter 1230: loss 1.2962, time 449.15ms, mfu 0.82%\n",
      "iter 1240: loss 1.2982, time 450.25ms, mfu 0.82%\n",
      "step 1250: train loss 1.2022, val loss 1.5028\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1250: loss 1.2697, time 61717.87ms, mfu 0.74%\n",
      "iter 1260: loss 1.2823, time 448.56ms, mfu 0.75%\n",
      "iter 1270: loss 1.2685, time 450.04ms, mfu 0.76%\n",
      "iter 1280: loss 1.2535, time 449.65ms, mfu 0.76%\n",
      "iter 1290: loss 1.2837, time 448.62ms, mfu 0.77%\n",
      "iter 1300: loss 1.2993, time 447.97ms, mfu 0.78%\n",
      "iter 1310: loss 1.2374, time 449.67ms, mfu 0.78%\n",
      "iter 1320: loss 1.2984, time 449.41ms, mfu 0.79%\n",
      "iter 1330: loss 1.2612, time 447.90ms, mfu 0.79%\n",
      "iter 1340: loss 1.2980, time 448.09ms, mfu 0.80%\n",
      "iter 1350: loss 1.2582, time 449.73ms, mfu 0.80%\n",
      "iter 1360: loss 1.2764, time 449.96ms, mfu 0.80%\n",
      "iter 1370: loss 1.2521, time 448.12ms, mfu 0.80%\n",
      "iter 1380: loss 1.2535, time 451.68ms, mfu 0.81%\n",
      "iter 1390: loss 1.2446, time 451.52ms, mfu 0.81%\n",
      "iter 1400: loss 1.2600, time 449.48ms, mfu 0.81%\n",
      "iter 1410: loss 1.2485, time 452.60ms, mfu 0.81%\n",
      "iter 1420: loss 1.2658, time 450.05ms, mfu 0.81%\n",
      "iter 1430: loss 1.2380, time 450.77ms, mfu 0.81%\n",
      "iter 1440: loss 1.2521, time 447.63ms, mfu 0.82%\n",
      "iter 1450: loss 1.2328, time 449.64ms, mfu 0.82%\n",
      "iter 1460: loss 1.2404, time 449.23ms, mfu 0.82%\n",
      "iter 1470: loss 1.2176, time 448.93ms, mfu 0.82%\n",
      "iter 1480: loss 1.2119, time 448.89ms, mfu 0.82%\n",
      "iter 1490: loss 1.2361, time 452.15ms, mfu 0.82%\n",
      "step 1500: train loss 1.1523, val loss 1.4786\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1500: loss 1.1889, time 61883.48ms, mfu 0.74%\n",
      "iter 1510: loss 1.2363, time 452.46ms, mfu 0.75%\n",
      "iter 1520: loss 1.2275, time 449.76ms, mfu 0.76%\n",
      "iter 1530: loss 1.2572, time 450.00ms, mfu 0.76%\n",
      "iter 1540: loss 1.1896, time 449.11ms, mfu 0.77%\n",
      "iter 1550: loss 1.2288, time 449.92ms, mfu 0.78%\n",
      "iter 1560: loss 1.2101, time 451.34ms, mfu 0.78%\n",
      "iter 1570: loss 1.2363, time 449.88ms, mfu 0.79%\n",
      "iter 1580: loss 1.2081, time 449.23ms, mfu 0.79%\n",
      "iter 1590: loss 1.1848, time 450.13ms, mfu 0.79%\n",
      "iter 1600: loss 1.2001, time 448.97ms, mfu 0.80%\n",
      "iter 1610: loss 1.2351, time 449.71ms, mfu 0.80%\n",
      "iter 1620: loss 1.1822, time 448.06ms, mfu 0.80%\n",
      "iter 1630: loss 1.2007, time 449.41ms, mfu 0.81%\n",
      "iter 1640: loss 1.1950, time 451.40ms, mfu 0.81%\n",
      "iter 1650: loss 1.1813, time 448.10ms, mfu 0.81%\n",
      "iter 1660: loss 1.2097, time 447.53ms, mfu 0.81%\n",
      "iter 1670: loss 1.1989, time 449.14ms, mfu 0.81%\n",
      "iter 1680: loss 1.1992, time 447.14ms, mfu 0.82%\n",
      "iter 1690: loss 1.2008, time 449.18ms, mfu 0.82%\n",
      "iter 1700: loss 1.1827, time 447.28ms, mfu 0.82%\n",
      "iter 1710: loss 1.1834, time 448.58ms, mfu 0.82%\n",
      "iter 1720: loss 1.1809, time 448.88ms, mfu 0.82%\n",
      "iter 1730: loss 1.1985, time 450.94ms, mfu 0.82%\n",
      "iter 1740: loss 1.1668, time 446.79ms, mfu 0.82%\n",
      "step 1750: train loss 1.1011, val loss 1.4620\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1750: loss 1.1910, time 61832.97ms, mfu 0.74%\n",
      "iter 1760: loss 1.1888, time 450.78ms, mfu 0.75%\n",
      "iter 1770: loss 1.1937, time 452.00ms, mfu 0.76%\n",
      "iter 1780: loss 1.1943, time 449.53ms, mfu 0.76%\n",
      "iter 1790: loss 1.1926, time 450.26ms, mfu 0.77%\n",
      "iter 1800: loss 1.1765, time 449.75ms, mfu 0.78%\n",
      "iter 1810: loss 1.1581, time 449.32ms, mfu 0.78%\n",
      "iter 1820: loss 1.1643, time 451.38ms, mfu 0.79%\n",
      "iter 1830: loss 1.1671, time 448.86ms, mfu 0.79%\n",
      "iter 1840: loss 1.1658, time 449.16ms, mfu 0.79%\n",
      "iter 1850: loss 1.1554, time 449.59ms, mfu 0.80%\n",
      "iter 1860: loss 1.1788, time 444.24ms, mfu 0.80%\n",
      "iter 1870: loss 1.1426, time 448.19ms, mfu 0.80%\n",
      "iter 1880: loss 1.1748, time 450.59ms, mfu 0.81%\n",
      "iter 1890: loss 1.1754, time 448.88ms, mfu 0.81%\n",
      "iter 1900: loss 1.1284, time 450.40ms, mfu 0.81%\n",
      "iter 1910: loss 1.1640, time 447.86ms, mfu 0.81%\n",
      "iter 1920: loss 1.1818, time 448.76ms, mfu 0.82%\n",
      "iter 1930: loss 1.1457, time 450.01ms, mfu 0.82%\n",
      "iter 1940: loss 1.1228, time 449.85ms, mfu 0.82%\n",
      "iter 1950: loss 1.1387, time 450.48ms, mfu 0.82%\n",
      "iter 1960: loss 1.1517, time 449.05ms, mfu 0.82%\n",
      "iter 1970: loss 1.1500, time 447.94ms, mfu 0.82%\n",
      "iter 1980: loss 1.1448, time 450.27ms, mfu 0.82%\n",
      "iter 1990: loss 1.1477, time 452.20ms, mfu 0.82%\n",
      "step 2000: train loss 1.0552, val loss 1.4756\n",
      "iter 2000: loss 1.1256, time 61545.29ms, mfu 0.74%\n",
      "iter 2010: loss 1.1248, time 447.96ms, mfu 0.75%\n",
      "iter 2020: loss 1.1219, time 449.60ms, mfu 0.76%\n",
      "iter 2030: loss 1.1544, time 449.26ms, mfu 0.76%\n",
      "iter 2040: loss 1.1384, time 449.61ms, mfu 0.77%\n",
      "iter 2050: loss 1.1120, time 449.03ms, mfu 0.78%\n",
      "iter 2060: loss 1.1029, time 448.68ms, mfu 0.78%\n",
      "iter 2070: loss 1.1277, time 446.72ms, mfu 0.79%\n",
      "iter 2080: loss 1.1165, time 449.03ms, mfu 0.79%\n",
      "iter 2090: loss 1.1249, time 448.11ms, mfu 0.80%\n",
      "iter 2100: loss 1.1282, time 447.63ms, mfu 0.80%\n",
      "iter 2110: loss 1.1342, time 448.25ms, mfu 0.80%\n",
      "iter 2120: loss 1.1304, time 449.67ms, mfu 0.81%\n",
      "iter 2130: loss 1.1389, time 452.74ms, mfu 0.81%\n",
      "iter 2140: loss 1.1392, time 447.42ms, mfu 0.81%\n",
      "iter 2150: loss 1.1175, time 452.49ms, mfu 0.81%\n",
      "iter 2160: loss 1.1506, time 449.26ms, mfu 0.81%\n",
      "iter 2170: loss 1.1404, time 449.07ms, mfu 0.81%\n",
      "iter 2180: loss 1.1095, time 448.07ms, mfu 0.82%\n",
      "iter 2190: loss 1.1033, time 451.21ms, mfu 0.82%\n",
      "iter 2200: loss 1.1191, time 449.73ms, mfu 0.82%\n",
      "iter 2210: loss 1.1070, time 451.02ms, mfu 0.82%\n",
      "iter 2220: loss 1.1195, time 450.60ms, mfu 0.82%\n",
      "iter 2230: loss 1.1161, time 445.68ms, mfu 0.82%\n",
      "iter 2240: loss 1.1221, time 450.49ms, mfu 0.82%\n",
      "step 2250: train loss 1.0095, val loss 1.4766\n",
      "iter 2250: loss 1.1019, time 61402.36ms, mfu 0.74%\n",
      "iter 2260: loss 1.1047, time 447.81ms, mfu 0.75%\n",
      "iter 2270: loss 1.1273, time 449.40ms, mfu 0.76%\n",
      "iter 2280: loss 1.0879, time 449.08ms, mfu 0.76%\n",
      "iter 2290: loss 1.1367, time 451.40ms, mfu 0.77%\n",
      "iter 2300: loss 1.1258, time 449.56ms, mfu 0.78%\n",
      "iter 2310: loss 1.0895, time 447.92ms, mfu 0.78%\n",
      "iter 2320: loss 1.0903, time 448.63ms, mfu 0.79%\n",
      "iter 2330: loss 1.0950, time 445.80ms, mfu 0.79%\n",
      "iter 2340: loss 1.1118, time 449.21ms, mfu 0.80%\n",
      "iter 2350: loss 1.0970, time 449.10ms, mfu 0.80%\n",
      "iter 2360: loss 1.1120, time 450.96ms, mfu 0.80%\n",
      "iter 2370: loss 1.0847, time 448.21ms, mfu 0.80%\n",
      "iter 2380: loss 1.0847, time 448.66ms, mfu 0.81%\n",
      "iter 2390: loss 1.0776, time 448.69ms, mfu 0.81%\n",
      "iter 2400: loss 1.0760, time 448.51ms, mfu 0.81%\n",
      "iter 2410: loss 1.0755, time 449.19ms, mfu 0.81%\n",
      "iter 2420: loss 1.0783, time 449.17ms, mfu 0.82%\n",
      "iter 2430: loss 1.0549, time 448.91ms, mfu 0.82%\n",
      "iter 2440: loss 1.0580, time 449.89ms, mfu 0.82%\n",
      "iter 2450: loss 1.0737, time 451.84ms, mfu 0.82%\n",
      "iter 2460: loss 1.0891, time 451.48ms, mfu 0.82%\n",
      "iter 2470: loss 1.0864, time 448.62ms, mfu 0.82%\n",
      "iter 2480: loss 1.0812, time 449.82ms, mfu 0.82%\n",
      "iter 2490: loss 1.0453, time 453.33ms, mfu 0.82%\n",
      "step 2500: train loss 0.9586, val loss 1.4994\n",
      "iter 2500: loss 1.0814, time 61391.78ms, mfu 0.74%\n",
      "iter 2510: loss 1.0688, time 449.78ms, mfu 0.75%\n",
      "iter 2520: loss 1.0512, time 448.77ms, mfu 0.76%\n",
      "iter 2530: loss 1.0408, time 448.88ms, mfu 0.76%\n",
      "iter 2540: loss 1.0551, time 450.17ms, mfu 0.77%\n",
      "iter 2550: loss 1.0688, time 449.73ms, mfu 0.78%\n",
      "iter 2560: loss 1.0544, time 453.61ms, mfu 0.78%\n",
      "iter 2570: loss 1.0725, time 451.92ms, mfu 0.79%\n",
      "iter 2580: loss 1.0844, time 451.59ms, mfu 0.79%\n",
      "iter 2590: loss 1.0696, time 450.97ms, mfu 0.79%\n",
      "iter 2600: loss 1.0632, time 451.21ms, mfu 0.80%\n",
      "iter 2610: loss 1.0401, time 451.75ms, mfu 0.80%\n",
      "iter 2620: loss 1.0372, time 452.08ms, mfu 0.80%\n",
      "iter 2630: loss 1.0179, time 452.21ms, mfu 0.80%\n",
      "iter 2640: loss 1.0445, time 451.48ms, mfu 0.81%\n",
      "iter 2650: loss 1.0681, time 449.27ms, mfu 0.81%\n",
      "iter 2660: loss 1.0366, time 452.59ms, mfu 0.81%\n",
      "iter 2670: loss 1.0169, time 448.94ms, mfu 0.81%\n",
      "iter 2680: loss 1.0504, time 451.66ms, mfu 0.81%\n",
      "iter 2690: loss 1.0509, time 450.20ms, mfu 0.81%\n",
      "iter 2700: loss 1.0217, time 447.88ms, mfu 0.82%\n",
      "iter 2710: loss 1.0422, time 449.13ms, mfu 0.82%\n",
      "iter 2720: loss 1.0433, time 452.17ms, mfu 0.82%\n",
      "iter 2730: loss 1.0564, time 449.32ms, mfu 0.82%\n",
      "iter 2740: loss 1.0189, time 448.30ms, mfu 0.82%\n",
      "step 2750: train loss 0.9139, val loss 1.5130\n",
      "iter 2750: loss 1.0318, time 61312.36ms, mfu 0.74%\n",
      "iter 2760: loss 1.0295, time 450.31ms, mfu 0.75%\n",
      "iter 2770: loss 1.0295, time 449.19ms, mfu 0.76%\n",
      "iter 2780: loss 1.0251, time 450.76ms, mfu 0.76%\n",
      "iter 2790: loss 1.0318, time 449.65ms, mfu 0.77%\n",
      "iter 2800: loss 1.0122, time 451.77ms, mfu 0.78%\n",
      "iter 2810: loss 1.0351, time 450.37ms, mfu 0.78%\n",
      "iter 2820: loss 1.0212, time 451.69ms, mfu 0.78%\n",
      "iter 2830: loss 1.0263, time 452.21ms, mfu 0.79%\n",
      "iter 2840: loss 0.9922, time 452.36ms, mfu 0.79%\n",
      "iter 2850: loss 1.0205, time 452.76ms, mfu 0.80%\n",
      "iter 2860: loss 1.0242, time 449.86ms, mfu 0.80%\n",
      "iter 2870: loss 1.0061, time 452.84ms, mfu 0.80%\n",
      "iter 2880: loss 1.0368, time 449.29ms, mfu 0.80%\n",
      "iter 2890: loss 1.0090, time 449.30ms, mfu 0.81%\n",
      "iter 2900: loss 0.9876, time 448.35ms, mfu 0.81%\n",
      "iter 2910: loss 1.0352, time 448.92ms, mfu 0.81%\n",
      "iter 2920: loss 1.0157, time 448.41ms, mfu 0.81%\n",
      "iter 2930: loss 0.9990, time 448.50ms, mfu 0.81%\n",
      "iter 2940: loss 0.9928, time 451.29ms, mfu 0.82%\n",
      "iter 2950: loss 1.0186, time 448.63ms, mfu 0.82%\n",
      "iter 2960: loss 0.9976, time 447.52ms, mfu 0.82%\n",
      "iter 2970: loss 0.9963, time 447.55ms, mfu 0.82%\n",
      "iter 2980: loss 0.9958, time 450.12ms, mfu 0.82%\n",
      "iter 2990: loss 0.9815, time 449.50ms, mfu 0.82%\n",
      "step 3000: train loss 0.8665, val loss 1.5220\n",
      "iter 3000: loss 0.9850, time 61416.40ms, mfu 0.74%\n",
      "iter 3010: loss 0.9859, time 450.27ms, mfu 0.75%\n",
      "iter 3020: loss 1.0010, time 451.78ms, mfu 0.76%\n",
      "iter 3030: loss 0.9986, time 450.80ms, mfu 0.76%\n",
      "iter 3040: loss 1.0249, time 450.09ms, mfu 0.77%\n",
      "iter 3050: loss 0.9766, time 450.44ms, mfu 0.78%\n",
      "iter 3060: loss 0.9964, time 447.45ms, mfu 0.78%\n",
      "iter 3070: loss 1.0165, time 446.17ms, mfu 0.79%\n",
      "iter 3080: loss 1.0097, time 449.72ms, mfu 0.79%\n",
      "iter 3090: loss 0.9833, time 449.17ms, mfu 0.79%\n",
      "iter 3100: loss 1.0001, time 449.25ms, mfu 0.80%\n",
      "iter 3110: loss 0.9759, time 447.90ms, mfu 0.80%\n",
      "iter 3120: loss 0.9977, time 446.74ms, mfu 0.80%\n",
      "iter 3130: loss 0.9721, time 450.47ms, mfu 0.81%\n",
      "iter 3140: loss 0.9786, time 448.03ms, mfu 0.81%\n",
      "iter 3150: loss 0.9971, time 446.82ms, mfu 0.81%\n",
      "iter 3160: loss 1.0064, time 449.84ms, mfu 0.81%\n",
      "iter 3170: loss 0.9650, time 448.14ms, mfu 0.82%\n",
      "iter 3180: loss 0.9730, time 449.00ms, mfu 0.82%\n",
      "iter 3190: loss 0.9958, time 447.14ms, mfu 0.82%\n",
      "iter 3200: loss 0.9680, time 450.02ms, mfu 0.82%\n",
      "iter 3210: loss 0.9696, time 448.07ms, mfu 0.82%\n",
      "iter 3220: loss 0.9523, time 447.52ms, mfu 0.82%\n",
      "iter 3230: loss 0.9500, time 448.29ms, mfu 0.82%\n",
      "iter 3240: loss 0.9532, time 450.28ms, mfu 0.82%\n",
      "step 3250: train loss 0.8214, val loss 1.5685\n",
      "iter 3250: loss 0.9688, time 61485.34ms, mfu 0.74%\n",
      "iter 3260: loss 0.9615, time 449.24ms, mfu 0.75%\n",
      "iter 3270: loss 0.9684, time 449.74ms, mfu 0.76%\n",
      "iter 3280: loss 0.9498, time 452.25ms, mfu 0.76%\n",
      "iter 3290: loss 0.9515, time 447.99ms, mfu 0.77%\n",
      "iter 3300: loss 0.9387, time 449.11ms, mfu 0.78%\n",
      "iter 3310: loss 0.9524, time 448.79ms, mfu 0.78%\n",
      "iter 3320: loss 0.9650, time 447.59ms, mfu 0.79%\n",
      "iter 3330: loss 0.9556, time 447.46ms, mfu 0.79%\n",
      "iter 3340: loss 0.9521, time 447.84ms, mfu 0.80%\n",
      "iter 3350: loss 0.9546, time 449.03ms, mfu 0.80%\n",
      "iter 3360: loss 0.9161, time 448.45ms, mfu 0.80%\n",
      "iter 3370: loss 0.9432, time 447.58ms, mfu 0.81%\n",
      "iter 3380: loss 0.9469, time 448.58ms, mfu 0.81%\n",
      "iter 3390: loss 0.9505, time 448.58ms, mfu 0.81%\n",
      "iter 3400: loss 0.9471, time 449.36ms, mfu 0.81%\n",
      "iter 3410: loss 0.9445, time 449.63ms, mfu 0.81%\n",
      "iter 3420: loss 0.9393, time 449.51ms, mfu 0.82%\n",
      "iter 3430: loss 0.9507, time 447.71ms, mfu 0.82%\n",
      "iter 3440: loss 0.9781, time 452.11ms, mfu 0.82%\n",
      "iter 3450: loss 0.9507, time 449.90ms, mfu 0.82%\n",
      "iter 3460: loss 0.9532, time 450.40ms, mfu 0.82%\n",
      "iter 3470: loss 0.9480, time 451.55ms, mfu 0.82%\n",
      "iter 3480: loss 0.9440, time 450.83ms, mfu 0.82%\n",
      "iter 3490: loss 0.9244, time 449.88ms, mfu 0.82%\n",
      "step 3500: train loss 0.7790, val loss 1.5732\n",
      "iter 3500: loss 0.9131, time 61406.90ms, mfu 0.74%\n",
      "iter 3510: loss 0.9098, time 450.54ms, mfu 0.75%\n",
      "iter 3520: loss 0.9239, time 448.95ms, mfu 0.76%\n",
      "iter 3530: loss 0.9526, time 447.51ms, mfu 0.76%\n",
      "iter 3540: loss 0.9304, time 448.46ms, mfu 0.77%\n",
      "iter 3550: loss 0.9261, time 452.16ms, mfu 0.78%\n",
      "iter 3560: loss 0.9500, time 448.58ms, mfu 0.78%\n",
      "iter 3570: loss 0.9428, time 447.71ms, mfu 0.79%\n",
      "iter 3580: loss 0.9355, time 448.99ms, mfu 0.79%\n",
      "iter 3590: loss 0.9234, time 448.51ms, mfu 0.80%\n",
      "iter 3600: loss 0.9256, time 448.82ms, mfu 0.80%\n",
      "iter 3610: loss 0.9132, time 448.04ms, mfu 0.80%\n",
      "iter 3620: loss 0.9116, time 448.73ms, mfu 0.80%\n",
      "iter 3630: loss 0.9225, time 450.36ms, mfu 0.81%\n",
      "iter 3640: loss 0.9257, time 453.24ms, mfu 0.81%\n",
      "iter 3650: loss 0.9150, time 446.52ms, mfu 0.81%\n",
      "iter 3660: loss 0.9371, time 449.03ms, mfu 0.81%\n",
      "iter 3670: loss 0.9412, time 450.72ms, mfu 0.81%\n",
      "iter 3680: loss 0.9091, time 450.79ms, mfu 0.82%\n",
      "iter 3690: loss 0.9308, time 450.27ms, mfu 0.82%\n",
      "iter 3700: loss 0.8638, time 449.51ms, mfu 0.82%\n",
      "iter 3710: loss 0.8850, time 450.23ms, mfu 0.82%\n",
      "iter 3720: loss 0.9073, time 451.83ms, mfu 0.82%\n",
      "iter 3730: loss 0.9030, time 450.83ms, mfu 0.82%\n",
      "iter 3740: loss 0.8995, time 451.74ms, mfu 0.82%\n",
      "step 3750: train loss 0.7403, val loss 1.5962\n",
      "iter 3750: loss 0.9005, time 61354.40ms, mfu 0.74%\n",
      "iter 3760: loss 0.9328, time 449.13ms, mfu 0.75%\n",
      "iter 3770: loss 0.9285, time 448.72ms, mfu 0.76%\n",
      "iter 3780: loss 0.9284, time 450.61ms, mfu 0.76%\n",
      "iter 3790: loss 0.8955, time 448.87ms, mfu 0.77%\n",
      "iter 3800: loss 0.9135, time 447.46ms, mfu 0.78%\n",
      "iter 3810: loss 0.9136, time 447.97ms, mfu 0.78%\n",
      "iter 3820: loss 0.8948, time 449.91ms, mfu 0.79%\n",
      "iter 3830: loss 0.9075, time 449.19ms, mfu 0.79%\n",
      "iter 3840: loss 0.8874, time 448.98ms, mfu 0.79%\n",
      "iter 3850: loss 0.8841, time 451.14ms, mfu 0.80%\n",
      "iter 3860: loss 0.8685, time 450.98ms, mfu 0.80%\n",
      "iter 3870: loss 0.8989, time 451.01ms, mfu 0.80%\n",
      "iter 3880: loss 0.8876, time 450.13ms, mfu 0.81%\n",
      "iter 3890: loss 0.9042, time 449.15ms, mfu 0.81%\n",
      "iter 3900: loss 0.8915, time 450.59ms, mfu 0.81%\n",
      "iter 3910: loss 0.8898, time 451.76ms, mfu 0.81%\n",
      "iter 3920: loss 0.8673, time 452.40ms, mfu 0.81%\n",
      "iter 3930: loss 0.8990, time 451.50ms, mfu 0.81%\n",
      "iter 3940: loss 0.8794, time 450.55ms, mfu 0.82%\n",
      "iter 3950: loss 0.8862, time 449.39ms, mfu 0.82%\n",
      "iter 3960: loss 0.9110, time 451.16ms, mfu 0.82%\n",
      "iter 3970: loss 0.8915, time 448.95ms, mfu 0.82%\n",
      "iter 3980: loss 0.8970, time 448.46ms, mfu 0.82%\n",
      "iter 3990: loss 0.8756, time 448.12ms, mfu 0.82%\n",
      "step 4000: train loss 0.7073, val loss 1.6318\n",
      "iter 4000: loss 0.8564, time 61332.27ms, mfu 0.74%\n",
      "iter 4010: loss 0.8836, time 447.60ms, mfu 0.75%\n",
      "iter 4020: loss 0.8876, time 450.35ms, mfu 0.76%\n",
      "iter 4030: loss 0.8817, time 449.19ms, mfu 0.76%\n",
      "iter 4040: loss 0.8787, time 449.74ms, mfu 0.77%\n",
      "iter 4050: loss 0.8665, time 448.68ms, mfu 0.78%\n",
      "iter 4060: loss 0.8622, time 451.56ms, mfu 0.78%\n",
      "iter 4070: loss 0.8684, time 451.92ms, mfu 0.79%\n",
      "iter 4080: loss 0.8798, time 451.27ms, mfu 0.79%\n",
      "iter 4090: loss 0.8532, time 449.38ms, mfu 0.79%\n",
      "iter 4100: loss 0.8939, time 449.93ms, mfu 0.80%\n",
      "iter 4110: loss 0.8736, time 451.39ms, mfu 0.80%\n",
      "iter 4120: loss 0.8760, time 452.31ms, mfu 0.80%\n",
      "iter 4130: loss 0.8579, time 452.49ms, mfu 0.80%\n",
      "iter 4140: loss 0.8808, time 448.55ms, mfu 0.81%\n",
      "iter 4150: loss 0.8691, time 449.33ms, mfu 0.81%\n",
      "iter 4160: loss 0.8567, time 448.12ms, mfu 0.81%\n",
      "iter 4170: loss 0.8647, time 448.58ms, mfu 0.81%\n",
      "iter 4180: loss 0.8667, time 445.19ms, mfu 0.82%\n",
      "iter 4190: loss 0.8729, time 446.09ms, mfu 0.82%\n",
      "iter 4200: loss 0.8557, time 447.81ms, mfu 0.82%\n",
      "iter 4210: loss 0.8768, time 448.63ms, mfu 0.82%\n",
      "iter 4220: loss 0.8645, time 447.79ms, mfu 0.82%\n",
      "iter 4230: loss 0.8877, time 449.13ms, mfu 0.82%\n",
      "iter 4240: loss 0.8621, time 446.32ms, mfu 0.82%\n",
      "step 4250: train loss 0.6797, val loss 1.6461\n",
      "iter 4250: loss 0.8737, time 61395.09ms, mfu 0.74%\n",
      "iter 4260: loss 0.8584, time 450.48ms, mfu 0.75%\n",
      "iter 4270: loss 0.8602, time 450.74ms, mfu 0.76%\n",
      "iter 4280: loss 0.8620, time 451.11ms, mfu 0.76%\n",
      "iter 4290: loss 0.8364, time 450.19ms, mfu 0.77%\n",
      "iter 4300: loss 0.8287, time 449.61ms, mfu 0.78%\n",
      "iter 4310: loss 0.8561, time 450.04ms, mfu 0.78%\n",
      "iter 4320: loss 0.8334, time 448.55ms, mfu 0.79%\n",
      "iter 4330: loss 0.8634, time 449.45ms, mfu 0.79%\n",
      "iter 4340: loss 0.8405, time 448.96ms, mfu 0.79%\n",
      "iter 4350: loss 0.8332, time 446.24ms, mfu 0.80%\n",
      "iter 4360: loss 0.8613, time 446.87ms, mfu 0.80%\n",
      "iter 4370: loss 0.8546, time 447.36ms, mfu 0.81%\n",
      "iter 4380: loss 0.8445, time 447.45ms, mfu 0.81%\n",
      "iter 4390: loss 0.8608, time 447.65ms, mfu 0.81%\n",
      "iter 4400: loss 0.8447, time 444.94ms, mfu 0.81%\n",
      "iter 4410: loss 0.8570, time 448.93ms, mfu 0.81%\n",
      "iter 4420: loss 0.8631, time 448.27ms, mfu 0.82%\n",
      "iter 4430: loss 0.8433, time 448.22ms, mfu 0.82%\n",
      "iter 4440: loss 0.8473, time 450.08ms, mfu 0.82%\n",
      "iter 4450: loss 0.8467, time 447.97ms, mfu 0.82%\n",
      "iter 4460: loss 0.8270, time 446.65ms, mfu 0.82%\n",
      "iter 4470: loss 0.8525, time 447.08ms, mfu 0.82%\n",
      "iter 4480: loss 0.8323, time 449.12ms, mfu 0.82%\n",
      "iter 4490: loss 0.8404, time 451.37ms, mfu 0.82%\n",
      "step 4500: train loss 0.6517, val loss 1.6728\n",
      "iter 4500: loss 0.8575, time 61452.46ms, mfu 0.74%\n",
      "iter 4510: loss 0.8502, time 450.79ms, mfu 0.75%\n",
      "iter 4520: loss 0.8503, time 448.50ms, mfu 0.76%\n",
      "iter 4530: loss 0.8527, time 448.19ms, mfu 0.77%\n",
      "iter 4540: loss 0.8416, time 447.74ms, mfu 0.77%\n",
      "iter 4550: loss 0.8734, time 447.57ms, mfu 0.78%\n",
      "iter 4560: loss 0.8358, time 447.96ms, mfu 0.78%\n",
      "iter 4570: loss 0.8504, time 447.51ms, mfu 0.79%\n",
      "iter 4580: loss 0.8529, time 450.00ms, mfu 0.79%\n",
      "iter 4590: loss 0.8554, time 445.43ms, mfu 0.80%\n",
      "iter 4600: loss 0.8265, time 448.41ms, mfu 0.80%\n",
      "iter 4610: loss 0.8580, time 445.90ms, mfu 0.80%\n",
      "iter 4620: loss 0.8324, time 448.35ms, mfu 0.81%\n",
      "iter 4630: loss 0.8306, time 447.00ms, mfu 0.81%\n",
      "iter 4640: loss 0.8470, time 449.32ms, mfu 0.81%\n",
      "iter 4650: loss 0.8638, time 450.64ms, mfu 0.81%\n",
      "iter 4660: loss 0.8447, time 450.83ms, mfu 0.81%\n",
      "iter 4670: loss 0.8397, time 451.91ms, mfu 0.82%\n",
      "iter 4680: loss 0.8422, time 449.18ms, mfu 0.82%\n",
      "iter 4690: loss 0.8406, time 449.96ms, mfu 0.82%\n",
      "iter 4700: loss 0.8222, time 449.84ms, mfu 0.82%\n",
      "iter 4710: loss 0.7886, time 451.45ms, mfu 0.82%\n",
      "iter 4720: loss 0.8214, time 452.66ms, mfu 0.82%\n",
      "iter 4730: loss 0.8226, time 451.25ms, mfu 0.82%\n",
      "iter 4740: loss 0.8386, time 448.81ms, mfu 0.82%\n",
      "step 4750: train loss 0.6362, val loss 1.6812\n",
      "iter 4750: loss 0.8048, time 61400.50ms, mfu 0.74%\n",
      "iter 4760: loss 0.8284, time 447.93ms, mfu 0.75%\n",
      "iter 4770: loss 0.8008, time 448.41ms, mfu 0.76%\n",
      "iter 4780: loss 0.8157, time 446.79ms, mfu 0.76%\n",
      "iter 4790: loss 0.8370, time 449.02ms, mfu 0.77%\n",
      "iter 4800: loss 0.8304, time 448.18ms, mfu 0.78%\n",
      "iter 4810: loss 0.8407, time 448.22ms, mfu 0.78%\n",
      "iter 4820: loss 0.8212, time 446.95ms, mfu 0.79%\n",
      "iter 4830: loss 0.8257, time 448.55ms, mfu 0.79%\n",
      "iter 4840: loss 0.8293, time 452.17ms, mfu 0.80%\n",
      "iter 4850: loss 0.8200, time 451.44ms, mfu 0.80%\n",
      "iter 4860: loss 0.8178, time 449.32ms, mfu 0.80%\n",
      "iter 4870: loss 0.8086, time 448.57ms, mfu 0.80%\n",
      "iter 4880: loss 0.8344, time 448.97ms, mfu 0.81%\n",
      "iter 4890: loss 0.8054, time 448.89ms, mfu 0.81%\n",
      "iter 4900: loss 0.8122, time 451.07ms, mfu 0.81%\n",
      "iter 4910: loss 0.8346, time 449.83ms, mfu 0.81%\n",
      "iter 4920: loss 0.8175, time 447.97ms, mfu 0.81%\n",
      "iter 4930: loss 0.8085, time 450.23ms, mfu 0.82%\n",
      "iter 4940: loss 0.8000, time 446.20ms, mfu 0.82%\n",
      "iter 4950: loss 0.8305, time 448.78ms, mfu 0.82%\n",
      "iter 4960: loss 0.8372, time 450.09ms, mfu 0.82%\n",
      "iter 4970: loss 0.7829, time 448.86ms, mfu 0.82%\n",
      "iter 4980: loss 0.7926, time 449.90ms, mfu 0.82%\n",
      "iter 4990: loss 0.8341, time 451.73ms, mfu 0.82%\n",
      "step 5000: train loss 0.6208, val loss 1.7024\n",
      "iter 5000: loss 0.8229, time 61228.13ms, mfu 0.74%\n"
     ]
    }
   ],
   "source": [
    "!python train.py config/train_shakespeare_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-shakespeare-char\n",
      "/home/ubuntu/diego/nanoGPT/sample.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device)\n",
      "number of parameters: 10.65M\n",
      "Loading meta from data/shakespeare_char/meta.pkl...\n",
      "\n",
      "\n",
      "Clown:\n",
      "So, who is here and the disposing of that\n",
      "hand all all all the hapless question?\n",
      "\n",
      "Servant:\n",
      "I am courted for a wizard with him.\n",
      "\n",
      "Shepherd:\n",
      "Ay, we'll buy good enter'd with the climation.\n",
      "\n",
      "AUTOLYCUS:\n",
      "A graciously word, and thus would by a cheeking how young\n",
      "have no more signal home.\n",
      "\n",
      "Clown:\n",
      "Say, on thou what evil seems to our father, if thou wilt show thy\n",
      "servant rugs for the great shepherd.\n",
      "\n",
      "MAMILLIUS:\n",
      "Pray, go on.\n",
      "\n",
      "Clown:\n",
      "Hark you, madam: but I am for his business, tell my to charge me.\n",
      "\n",
      "\n",
      "---------------\n",
      "\n",
      "MENENIUS:\n",
      "I must thou answer'd me\n",
      "That with the noble two men.\n",
      "\n",
      "CORIOLANUS:\n",
      "What then?\n",
      "\n",
      "CORIOLANUS:\n",
      "The speaks I that love\n",
      "In all the people.\n",
      "\n",
      "CORIOLANUS:\n",
      "The veril is scopen'd in meeting.\n",
      "\n",
      "VOLUMNIA:\n",
      "Why, my lord?\n",
      "\n",
      "VOLUMNIA:\n",
      "Nay, not I.\n",
      "\n",
      "CORIOLANUS:\n",
      "You have not a king,\n",
      "For that we must be forget and death old and criving\n",
      "From Isabell'd. I know the noise of this man this of Mistresses'\n",
      "Conceal to the ground of the possessession. Your love\n",
      "Is nothing the victory time in our terror;\n",
      "Look to what e\n",
      "---------------\n",
      "\n",
      "MARIANA:\n",
      "I beseech you, I would were dead.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "To have that had her well been so much in her worse.\n",
      "\n",
      "MARIANA:\n",
      "No, my lord.\n",
      "\n",
      "ISABELLA:\n",
      "Not sir.\n",
      "\n",
      "ISABELLA:\n",
      "You are it but fasting your face,\n",
      "Like me a suitor for in me. Conventinue,\n",
      "Or would in the determine of the part,\n",
      "Blows of gracious rebels just defendant.\n",
      "\n",
      "ANGELO:\n",
      "This is some night, stand by back and profess\n",
      "Against substrange of voices, that you love your wholesomething\n",
      "With your wrecked prince, and find your honour's langural,\n",
      "\n",
      "---------------\n",
      "\n",
      "The smooth is now a bar-day, strew him\n",
      "In but of all the corous to the enemy:\n",
      "Where his, should be gone, and he hath been patient,\n",
      "The townright of my should will be holy as it\n",
      "As could have bear some near of the hardy labour,\n",
      "And thine eyes hath swark'd in the city, of monuments\n",
      "Which he says to see the power 'Would they were peace,\n",
      "A little spurit of the duke cause; 'tis not.\n",
      "\n",
      "CORIOLANUS:\n",
      "March on, I would I would to see them\n",
      "And see what is to swear down.\n",
      "\n",
      "AUFIDIUS:\n",
      "For who were I won a man a\n",
      "---------------\n",
      "\n",
      "BUCKINGHAM:\n",
      "Then, here come your lord.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, so the dead must have been a world\n",
      "With his song a world of late and his eyes?\n",
      "Tempt hers and do play it together;\n",
      "And put in that you at my heart's mind\n",
      "End his mouth to him; he lies upon your soldiers,\n",
      "More light upon his tongues, and with his mind\n",
      "To frown and humour his soul.\n",
      "\n",
      "Clown:\n",
      "Let's heaven, I speak, that you be hope of most stroke\n",
      "Your eyes, my brother, that he is pass'd,\n",
      "I'ld you forget him for such a best.\n",
      "\n",
      "AUTOLYCUS:\n",
      "A ge\n",
      "---------------\n",
      "\n",
      "\n",
      "MENENIUS:\n",
      "Have been so to a goodly woman.\n",
      "\n",
      "CORIOLANUS:\n",
      "Away!\n",
      "\n",
      "First Servingman:\n",
      "Nay, be how now; that's a man of all.\n",
      "\n",
      "Second Servingman:\n",
      "This is a witness and sleep: it is but this in their\n",
      "fellows. A man a servant of it! This is the crown kings of the\n",
      "mistress, and this will be graved of all of water'd, and\n",
      "Bear it yet to knowledge our company: it is cold that the\n",
      "Give your lady; which will thou live a little sort\n",
      "Which will riise you have been drawn'd him shall death\n",
      "And to drink you that pl\n",
      "---------------\n",
      "\n",
      "She was served his blood against his sheep-sequing winds,\n",
      "A man to her good man in her to speak.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Nor here, not to see him of death:\n",
      "You rage it, good my order is not my lord.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Say you to your purse nor of your grace and have been\n",
      "To prison, my sister, but who is the may be with joy.\n",
      "\n",
      "LUCENTIO:\n",
      "Have you here all father too.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Be no pretties a barren?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Marry you, my lord; but you will pard your gates of suit.\n",
      "\n",
      "ANGELO:\n",
      "And little for y\n",
      "---------------\n",
      "\n",
      "I have hence, lord, tell him her mind;\n",
      "And there a devision cannot be gone,\n",
      "To save the man you and bow of my love,\n",
      "As you will written yourself, will I wish\n",
      "You have done: but yet I have done so,\n",
      "So pray your voices in my hands, whereof,\n",
      "Know her to your eyes and sharp tears.\n",
      "\n",
      "JULIET:\n",
      "And rather have you quite him dead!\n",
      "\n",
      "Nurse:\n",
      "Here's gone, whom your ransoment; and so we are more\n",
      "To make the halber-day to make a child-blood,--O brave me!--\n",
      "And as it is your son, sir, when you must be discover'd\n",
      "---------------\n",
      "\n",
      "\n",
      "LEONTES:\n",
      "The realm of thy master\n",
      "In's blood to my virtuous pack: but whose wes\n",
      "Hast thou in thee, so much sick, when\n",
      "Malm of thy brother, though they have made me and\n",
      "To make me or such time to comport. What, I must please\n",
      "In that very flower as thou outch of word,\n",
      "And thy son is and smile vexation.\n",
      "\n",
      "Nurse:\n",
      "I fear, I have done as if thou gave me there:\n",
      "The blood will is it word to this.\n",
      "\n",
      "CLARENCE:\n",
      "How thou hast not servant, which wilt thou be a king!\n",
      "Wilt thou the ruthless fellow?\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "---------------\n",
      "\n",
      "How cheerful rather and her eyes\n",
      "Which for that I am here in the people,\n",
      "Having been commended and the roses of such births,\n",
      "Shows forth, if thou the sickly be enough,\n",
      "And not have no more wrong'd with his own.\n",
      "Nor who is yours of royal pity of Buckingham,\n",
      "Which you for his land-fortune with us,\n",
      "So virtuous like prayers for our concils\n",
      "Full of his foes, that all dearame mercy,\n",
      "Your noble was a wife of your graces\n",
      "With either dearth, your hardy devise,\n",
      "And the itself of her brother, I did not see\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python sample.py --out_dir=out-shakespeare-char"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
